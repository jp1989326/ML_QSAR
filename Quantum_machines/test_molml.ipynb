{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "#import sys\n",
    "#sys.path.append('../')\n",
    "import timeit\n",
    "import h5py\n",
    "import molml\n",
    "from molml.features import CoulombMatrix, BagOfBonds\n",
    "from molml.features import LocalCoulombMatrix\n",
    "from molml.kernel import AtomKernel\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.ensemble import RandomForestRegressor as rfr\n",
    "from sklearn.metrics import r2_score,mean_squared_error, mean_absolute_error, median_absolute_error\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler \n",
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#load molecule data, the coordinate, atom_number, elements are essential as the input \n",
    "\n",
    "attrs_list =[ 'atom_number', 'data_base', 'atom_list', 'atom_coordinate_list', 'frequency_list','target_list',\\\n",
    "          'smile_list', 'atom_charge']\n",
    "\n",
    "metrics = [r2_score, mean_absolute_error, mean_squared_error, median_absolute_error]\n",
    "\n",
    "def load_133k(num = None):\n",
    "    \n",
    "    data_path = '/home/peng/Documents/Project_C/QSAR_nlp/Dataset_qm9/'\n",
    "    data_set = \"133K.hdf5\"\n",
    "\n",
    "    coord_list = []\n",
    "    element_list = []\n",
    "    target_list = []\n",
    "    atom_no_list = []\n",
    "    \n",
    "\n",
    "    f = h5py.File(data_path + data_set, \"r\")\n",
    "    if not num:\n",
    "        limit = len(f)+1\n",
    "    else:\n",
    "        limit = num\n",
    "        \n",
    "    for i in range(1, limit):\n",
    "        str_element = str(f[str(i)].attrs[attrs_list[2]], 'utf-8')\n",
    "        split_str = []\n",
    "        for j in str_element:\n",
    "            split_str.append(j)\n",
    "        element_list.append(np.array(split_str))\n",
    "        coord_list.append(f[str(i)].attrs[attrs_list[3]])    \n",
    "        target_list.append(f[str(i)].attrs[attrs_list[-3]]) \n",
    "        atom_no_list.append(f[str(i)].attrs[attrs_list[0]])   \n",
    "        if i %100000 == 0:\n",
    "            print (\"already finish \", i)\n",
    "    f.close()\n",
    "    \n",
    "    #df = pd.DataFrame({'coord':coord_list, 'element':element_list, 'target':target_list})\n",
    "    \n",
    "    return element_list, coord_list, target_list, atom_no_list\n",
    "\n",
    "def get_attributes(element_list, coord_list, target_list):\n",
    "\n",
    "    fit_list = []\n",
    "#    target_single_list = []\n",
    "    for i in range(0, len(element_list)):\n",
    "        fit_list.append((element_list[i], coord_list[i]))\n",
    "#        target_single_list.append(target_list[i][-1])\n",
    "        \n",
    "    return fit_list #, target_single_list   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_train_list(num=None):\n",
    "\n",
    "    # extract the element, the coordinates, the targets and the atom_no from the 133k dataset\n",
    "    element_list, coord_list, target_list, atom_no_list = load_133k(num)\n",
    "    # generate the (element, coordinate) tuple for following feature engineering\n",
    "    fit_list = get_attributes(element_list, coord_list, target_list)\n",
    "    return fit_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the input, bob features and targets from csv, and generate train test, train_validation sets\n",
    "from ast import literal_eval\n",
    "df = pd.read_csv('bob_targets15.csv', header = 0)\n",
    "\n",
    "fit_list = get_train_list(num=3)\n",
    "#df_list_bob = df['bob']\n",
    "\n",
    "#df_list_newbob = df_list_bob.apply(lambda x : literal_eval(x))\n",
    "\n",
    "#train_list = (df_list_newbob)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['C', 'H', 'H', 'H', 'H'], \n",
       "       dtype='<U1'),\n",
       " array([[ -1.26981359e-02,   1.08580416e+00,   8.00099580e-03],\n",
       "        [  2.15041600e-03,  -6.03131760e-03,   1.97612040e-03],\n",
       "        [  1.01173084e+00,   1.46375116e+00,   2.76574800e-04],\n",
       "        [ -5.40815069e-01,   1.44752661e+00,  -8.76643715e-01],\n",
       "        [ -5.23813634e-01,   1.43793264e+00,   9.06397294e-01]]))"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate feature engineered input features, CM or BOB\n",
    "feature_methods = [CoulombMatrix(), BagOfBonds()]\n",
    "feat_co = feature_methods[1]\n",
    "train_list = feat_co.fit_transform(fit_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5.49477531,  5.49476946,  5.49474894,  5.49474169,  0.56081483,\n",
       "         0.5608061 ,  0.56080599,  0.56080582,  0.56080321,  0.56080291,\n",
       "         0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.61784735,\n",
       "         0.61777757,  0.61777591,  0.        ,  0.        ,  0.        ,\n",
       "         6.88172254,  6.88170334,  6.88158238]])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
